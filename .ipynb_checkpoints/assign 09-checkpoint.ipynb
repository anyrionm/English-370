{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b40db3d5-b011-49a3-9dda-d758a19dfd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import re\n",
    "import nltk\n",
    "from pathlib import Path\n",
    "\n",
    "# CUSTOM TOKENIZER\n",
    "# This function takes a string and returns a list of tokens\n",
    "# QUIZ COMMENT: Could this function be improved?\n",
    "def tknize (a_string):\n",
    "    words = re.sub('[^a-zA /.]', ' ', a_string).split()\n",
    "    return words\n",
    "\n",
    "# TEST DATA\n",
    "# with open(\"../data/Romance\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "    # Romance = f.read()\n",
    "\n",
    "#SINGLE TEXT\n",
    "with open(\"data/Romance/bodyguard.txt\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "    bodyguard = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f35ec77-d9b1-4c52-8433-14129891cefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'ritten', 'by', 'A', 'A']\n",
      "['A', 'ritten', 'by', 'A', 'A']\n"
     ]
    }
   ],
   "source": [
    "#Test our tokenizer\n",
    "Romance_ = tknize(bodyguard)\n",
    "bodyguard_ = tknize(bodyguard)\n",
    "print(Romance_[0:5])\n",
    "print(bodyguard_[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51997aaf-d2b4-471b-8858-5f0bf64b7c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'DT'),\n",
       " ('ritten', 'NN'),\n",
       " ('by', 'IN'),\n",
       " ('A', 'NNP'),\n",
       " ('A', 'NNP'),\n",
       " ('A', 'NNP'),\n",
       " ('lean', 'JJ'),\n",
       " ('hooting', 'NN'),\n",
       " ('raft', 'NN'),\n",
       " ('ebruary', 'VBP')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mdg_ is our cleaned list of tokens whick keeps only periods.\n",
    "bodyguard_tagged = nltk.pos_tag(bodyguard_)\n",
    "bodyguard_tagged[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca9114be-6b3d-4097-8dca-9447e28b85fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lean\n"
     ]
    }
   ],
   "source": [
    "for t in bodyguard_tagged[0:10]:\n",
    "    if t[1] == 'JJ':\n",
    "        print(t[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fef5146-ee4f-4a5d-8644-c047769400a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Armani', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Again', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'America.', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'All', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Alexander', 'A', 'A', 'A', 'A', 'A', 'A', 'Are', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', '...And', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Akron.', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Are', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Academy', 'Awards.', 'A', 'Actress', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', '/', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Are', 'A', 'A', 'A', 'A', 'A', 'A', 'Angeles.', 'Are', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Are', 'A', 'A', 'A', 'A', 'A', '.A.', 'A', 'As', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Are', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Anyone', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'All', 'A', 'Aren', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', '.A.', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Agent', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Absolutely.', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Academy', 'Award', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Ambassador', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Actress', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Amid', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Anyway', 'A', 'A', 'Ah...', 'A', 'A', 'Are', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Assured', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Agents', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', '.A.', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Anyway', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Are', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'you.', 'A', 'A', 'A', 'A', 'A', '...Armando...', 'A', 'A', '.A.', 'Armando.', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Are', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Academy', 'Awards', 'A', 'A', 'A', 'Applause.', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Applause', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Anne', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Are', 'A', 'A', 'A', 'A', 'Actress', 'A', 'kip', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Academy.', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', '...and', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'As', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'Against', 'A', 'A', 'A', 'A', 'A', 'Armani', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'All', 'Amen.', 'A']\n"
     ]
    }
   ],
   "source": [
    "# Let's find all the proper nouns:\n",
    "bodyguard_nouns = []\n",
    "for i in bodyguard_tagged:\n",
    "    if i[1] == \"NNP\":\n",
    "        bodyguard_nouns.append(i[0])\n",
    "\n",
    "print(bodyguard_nouns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "65259e3a-0313-4d47-a36c-1b4bd7c5a822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPOS (POS, a_string):\n",
    "    tokens = tknize(a_string)\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    the_list = []\n",
    "    for i in tagged:\n",
    "        if i[1] == POS:\n",
    "            the_list.append(i[0])\n",
    "            \n",
    "    return the_list\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f64f9d0b-9997-4847-b159-b2b3c6bbe57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A']\n"
     ]
    }
   ],
   "source": [
    "# Test on toy data\n",
    "nouns = getPOS(\"NNP\", bodyguard)\n",
    "print(nouns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1511be0d-df6f-4857-8f5d-43f25e0a27f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A']\n"
     ]
    }
   ],
   "source": [
    "# Test on a single text from our corpus\n",
    "nouns = getPOS(\"NNP\", bodyguard)\n",
    "print(nouns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "922f69b6-3016-4667-9cb5-73de33989dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all screenplays\n",
    "screenplays = []\n",
    "for p in Path('data/Romance/bodyguard/').glob('*.txt'):\n",
    "    with open(p, encoding=\"utf8\", errors=' ignore') as f:\n",
    "        contents = f.read()\n",
    "        screenplays.append(contents)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "767d33e2-8475-4729-8715-f50f26ec9b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The one function to rule them all\n",
    "def removePNs(a_string):\n",
    "    tokens = re.sub('[^a-zA-Z /.]', ' ', a_string).split()\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    the_list = []\n",
    "    for i in tagged:\n",
    "        if i[1] == \"NNP\":\n",
    "            the_list.append(i[0])\n",
    "    toremove = list(set(the_list))\n",
    "    filtered = []\n",
    "    for token in tokens:\n",
    "        if token not in toremove:\n",
    "            filtered.append(token)\n",
    "        return \" \".join(filtered)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bc8a725b-c0af-449e-a715-a50bdfd2b149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test on a single text from our corpus\n",
    "bodyguard = removePNs(bodyguard)\n",
    "print(bodyguard[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e63828f1-8ed2-4773-87a1-1f659556a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use on all screenplays\n",
    "texts = [removePNs(text) for text in screenplays]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42822dd-4474-4e3a-aa39-794f7beb35f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
